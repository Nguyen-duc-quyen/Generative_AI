{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "import sys\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "\n",
    "#from torchvision import transforms\n",
    "from torchvision.transforms import v2 # for torchvision > 0.15\n",
    "import torch.nn as nn\n",
    "import torcheval.metrics as metrics\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataloaders import *\n",
    "from utils.preprocessing import *\n",
    "from utils.training_utils import *\n",
    "from utils.metrics import *\n",
    "from utils.losses import *\n",
    "\n",
    "from datasets.load_cifar10 import *\n",
    "\n",
    "from denoising_autoencoder.models import *\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/CIFAR10/cifar-10-batches-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_filenames, train_labels, test_images, test_filenames, test_labels, label_names = load_cifar10(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image scaling\n",
    "train_images = train_images/255\n",
    "test_images = test_images/255\n",
    "\n",
    "# Calculate mean and std\n",
    "\"\"\"\n",
    "mean = []\n",
    "std = []\n",
    "\n",
    "for i in range(train_images.shape[-1]):\n",
    "    mean.append(np.mean(train_images[:, :, :, i]))\n",
    "    std.append(np.std(train_images[:, :, :, i]))\n",
    "\"\"\"\n",
    "mean = np.mean(train_images, axis=(0, 1, 2))\n",
    "std = np.std(train_images, axis=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.ToTensor(), # deprecated # Will transpose the image, since torch expected the input image to be of shape [H, W, C] -> [C, H, W]\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "    AddDropoutNoise(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CifarGenerativeDataset(images=train_images, transforms=train_transform)\n",
    "test_dataset = CifarGenerativeDataset(images=test_images, transforms=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "in_channels = 3\n",
    "enc_hidden_channels = 16\n",
    "emb_channels = 4\n",
    "dec_hidden_channels = 16\n",
    "\n",
    "# Training configuration\n",
    "epochs = 25\n",
    "batchsize = 128\n",
    "learning_rate = 0.001\n",
    "num_workers = 4\n",
    "device = \"cuda\"\n",
    "use_wandb = True\n",
    "use_tensorboard = False\n",
    "\n",
    "# Checkpoint dir\n",
    "save_dir = \".\\checkpoints\"\n",
    "exp_name = \"denoising_conv_autoencoder_{}\".format(str(date.today()))\n",
    "save_dir = os.path.join(save_dir, exp_name)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.system(\"mkdir {}\".format(save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(train_dataset, batchsize, num_workers, shuffle=True, drop_last=False)\n",
    "test_loader = get_loader(test_dataset, batchsize, num_workers, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv_AutoEncoder(in_channels, enc_hidden_channels, emb_channels, dec_hidden_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    # The first thre metrics only work on images\n",
    "    metrics.FrechetInceptionDistance(device=device), # Only work on three-channel images\n",
    "    # metrics.StructuralSimilarity(device=device),\n",
    "    metrics.PeakSignalNoiseRatio(device=device),\n",
    "    # metrics.MeanSquaredError(device=device)\n",
    "]\n",
    "metric_weights = [1.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    # initialize wandb for usage\n",
    "    wandb.login()\n",
    "    wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"denoising-conv-cifar-10-autoencoder\", \n",
    "        # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "        name=exp_name, \n",
    "        # Track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"architecture\": str(model.__class__.__name__),\n",
    "            \"dataset\": \"MNIST\",\n",
    "            \"epochs\": epochs,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func,\n",
    "    metrics=metrics,\n",
    "    metric_weights=metric_weights,\n",
    "    device=device,\n",
    "    num_epochs=epochs,\n",
    "    log_rate=5,\n",
    "    save_rate=10,\n",
    "    save_dir=save_dir,\n",
    "    use_tensorboard=use_tensorboard,\n",
    "    use_wandb=use_wandb,\n",
    "    interval=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
